# ARPO Replication - Complete Setup

**Status**: âœ… Setup Complete | ğŸ¯ Ready for GPU Inference Testing

This repository contains a complete ARPO replication with tested inference pipeline for OSWorld GUI tasks.

---

## ğŸ“Š Performance Findings

### CPU Performance (UI-TARS-2B on Mac):
- **Per step**: ~60 minutes (47-88 min range)
- **Per task** (10 steps): ~10 hours  
- **Training** (8 tasks Ã— 5 epochs): ~400 hours (16.7 days)
- **Conclusion**: âŒ Not practical for training

### GPU Performance (Expected with UI-TARS-7B):
- **Per step**: 2-5 seconds (100-200x faster)
- **Per task**: 20-50 seconds
- **Training** (128 tasks Ã— 15 epochs): 5-15 hours
- **Conclusion**: âœ… Practical and matches paper

---

## ğŸ“ Project Structure

```
ARPO_replicate/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ START_HERE.md           # Quick start guide
â”‚   â”œâ”€â”€ TRAINING_GUIDE.md       # Complete training instructions
â”‚   â”œâ”€â”€ PAPER_SUMMARY.md        # ARPO paper deep dive
â”‚   â”œâ”€â”€ PERFORMANCE_REPORT.md   # CPU/GPU performance analysis
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md      # Problem solving
â”‚   â””â”€â”€ FILES.md                # File overview
â”‚
â”œâ”€â”€ configs/                     # Training configurations
â”‚   â””â”€â”€ config_uitars_2b_mac.yaml  # VERL training config
â”‚
â”œâ”€â”€ scripts/                     # Executable scripts
â”‚   â”œâ”€â”€ uitars_2b_server.py     # UI-TARS-2B inference server (CPU tested)
â”‚   â”œâ”€â”€ uitars_7b_server.py     # UI-TARS-7B inference server (GPU)
â”‚   â”œâ”€â”€ train_uitars_2b_arpo.sh # Training script (2B)
â”‚   â”œâ”€â”€ test_server.sh          # Server test
â”‚   â”œâ”€â”€ test_single_task.sh     # Single task test
â”‚   â””â”€â”€ test_osworld_uitars.sh  # OSWorld integration test
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks
â”‚   â”œâ”€â”€ ARPO_UITARS_Inference.ipynb      # GPU inference (tested) â­
â”‚   â”œâ”€â”€ ARPO_OSWorld_Evaluation.ipynb    # Evaluation on 10 tasks (NEW) â­
â”‚   â””â”€â”€ arpo_training_notebook.ipynb     # Training guide
â”‚
â”œâ”€â”€ test_data/                   # Test tasks
â”‚   â””â”€â”€ osworld_examples/
â”‚       â”œâ”€â”€ tasks/              # 5 original tasks
â”‚       â””â”€â”€ noisy_tasks/        # 5 noisy tasks
â”‚
â”œâ”€â”€ OSWorld/                     # OSWorld benchmark (submodule)
â”œâ”€â”€ verl/                        # VERL training framework  
â””â”€â”€ examples/                    # Example training scripts
```

---

## ğŸš€ Quick Start

### For GPU Inference Testing (Colab/VSCode):

1. **Open notebook**:
   ```bash
   notebooks/ARPO_OSWorld_Evaluation.ipynb
   ```

2. **Run all cells** - It will:
   - Load ARPO UITARS 7B model (4-bit quantized)
   - Test on 5 original + 5 noisy OSWorld tasks
   - Generate results and metrics

**Time**: ~30-60 minutes on A100 GPU

### For CPU Testing (Mac):

See `docs/START_HERE.md` for CPU setup (not recommended for training).

---

## ğŸ“Š Test Data

**From**: [gowathena/arpo_replica/tree/data](https://github.com/gowathena/arpo_replica/tree/data)

**Tasks**:
- **5 Original tasks**: Standard OSWorld Chrome tasks
- **5 Noisy tasks**: Same tasks with distractor entries

**Format**: Compatible with OSWorld evaluation_examples

---

## ğŸ¯ Models

### UI-TARS-2B (Tested on CPU):
- **Model**: ByteDance-Seed/UI-TARS-2B-SFT
- **Size**: 2B parameters
- **Performance**: ~60 min/step on CPU
- **Use**: Development/testing only

### UI-TARS-7B (For GPU):
- **Model**: [Fanbin/ARPO_UITARS1.5_7B](https://huggingface.co/Fanbin/ARPO_UITARS1.5_7B) â­
- **Size**: 7B parameters (ARPO-trained)
- **Performance**: 2-5 sec/step on GPU
- **Results**: 83.9% on 128 tasks, 29.9% overall
- **Use**: Production training/evaluation

---

## ğŸ”§ Setup

### Requirements:
- Python 3.10+
- For GPU: CUDA 11.8+, 16GB+ VRAM
- For CPU: 16GB+ RAM (very slow, not recommended)

### Install:
```bash
pip install -r requirements.txt
```

### OSWorld Setup (Optional):
Only needed for full training, not for inference testing with notebooks.

See `docs/START_HERE.md` for complete setup.

---

## ğŸ“– Documentation

- **Quick Start**: `docs/START_HERE.md`
- **Training Guide**: `docs/TRAINING_GUIDE.md`
- **Paper Summary**: `docs/PAPER_SUMMARY.md`
- **Performance**: `docs/PERFORMANCE_REPORT.md`
- **Troubleshooting**: `docs/TROUBLESHOOTING.md`

---

## ğŸ“ What This Repository Provides

1. âœ… **Complete ARPO environment**
2. âœ… **Tested inference pipeline** (CPU with 2B, ready for GPU with 7B)
3. âœ… **OSWorld integration**
4. âœ… **Test data** (10 tasks: 5 original + 5 noisy)
5. âœ… **Training scripts** (VERL framework configured)
6. âœ… **Comprehensive documentation**

---

## ğŸ“ Citation

```bibtex
@article{lu2025arpo,
  title={ARPO: End-to-End Policy Optimization for GUI Agents with Experience Replay},
  author={Fanbin Lu and Zhisheng Zhong and Shu Liu and Chi-Wing Fu and Jiaya Jia},
  journal={arXiv},
  year={2025}
}
```

---

## ğŸ”— Links

- **Paper**: [arXiv](https://arxiv.org/abs/2505.16282)
- **Original Code**: [JIA-Lab-research/ARPO](https://github.com/JIA-Lab-research/ARPO)
- **ARPO Model**: [Fanbin/ARPO_UITARS1.5_7B](https://huggingface.co/Fanbin/ARPO_UITARS1.5_7B)
- **OSWorld**: [xlang-ai/OSWorld](https://github.com/xlang-ai/OSWorld)

---

**Ready to test with GPU!** ğŸš€ See `notebooks/ARPO_OSWorld_Evaluation.ipynb`
