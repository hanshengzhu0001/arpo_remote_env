{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ARPO Smoke Test - VERL Pipeline Verification\n",
        "\n",
        "**Stage 1: Wiring / Smoke Run**\n",
        "\n",
        "Minimal test to verify ARPO training pipeline works:\n",
        "- 4 tasks only\n",
        "- 2 Docker environments\n",
        "- ~100-200 optimizer steps\n",
        "\n",
        "## Success Criteria\n",
        "- \u2705 Loss is finite and changes\n",
        "- \u2705 Checkpoints save successfully\n",
        "- \u2705 Can resume from checkpoint\n",
        "- \u2705 Evaluation loads checkpoint\n",
        "\n",
        "**Expected time: ~30-60 minutes on A100**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Check GPU (A100)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "!nvidia-smi\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    raise RuntimeError(\"GPU required!\")\n",
        "print(f\"\u2705 {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Clone Repo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "token = getpass('GitHub token: ')\n",
        "!git clone https://{token}@github.com/gowathena/arpo_replica.git\n",
        "%cd arpo_replica\n",
        "!git checkout arpo-cpu-replicate\n",
        "!git submodule update --init --recursive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Install"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core ML\n",
        "%pip install -q torch==2.5.1 transformers>=4.45.0 accelerate\n",
        "\n",
        "# VERL framework dependencies (from requirements.txt)\n",
        "%pip install -q ray omegaconf wandb tqdm psutil\n",
        "%pip install -q tensordict datasets\n",
        "%pip install -q codetiming filelock\n",
        "%pip install -q mathruler  # Required by VERL reward scoring\n",
        "\n",
        "# Model\n",
        "%pip install -q qwen-vl-utils pillow\n",
        "\n",
        "# Install OSWorld\n",
        "%cd OSWorld  \n",
        "%pip install -q -r requirements.txt\n",
        "%pip install -q -e .\n",
        "%cd ..\n",
        "\n",
        "print('\u2705 All dependencies installed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Setup"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Docker\n",
        "!sudo service docker start\n",
        "!docker pull happysixd/osworld-docker:latest\n",
        "\n",
        "# Ray\n",
        "import ray\n",
        "ray.init(num_cpus=4, num_gpus=1, ignore_reinit_error=True)\n",
        "\n",
        "# wandb\n",
        "import wandb, os\n",
        "from getpass import getpass\n",
        "os.environ['WANDB_API_KEY'] = getpass('wandb key: ')\n",
        "wandb.login()\n",
        "\n",
        "# Update for Docker\n",
        "!sed -i 's/vmware/docker/g' OSWorld/run_uitars.py\n",
        "!sed -i 's/vmware/docker/g' OSWorld/run_multienv_uitars.py\n",
        "\n",
        "print('\u2705 Setup complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Smoke Test Config"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "config = {\n",
        "    'data': {\n",
        "        'train_files': 'test_data/osworld_examples/train_smoke_4.json',\n",
        "        'val_files': 'test_data/osworld_examples/train_smoke_4.json',\n",
        "        'prompt_key': 'instruction',\n",
        "        'max_prompt_length': 16384,\n",
        "        'max_response_length': 2048,\n",
        "    },\n",
        "    'algorithm': {\n",
        "        'adv_estimator': 'grpo',  # ARPO uses GRPO\n",
        "        'disable_kl': True,\n",
        "        'kl_coef': 0,\n",
        "        'enable_replay': True,  # Experience replay (key ARPO feature!)\n",
        "    },\n",
        "    'worker': {\n",
        "        'actor': {\n",
        "            'global_batch_size': 2,\n",
        "            'micro_batch_size_per_device_for_update': 1,\n",
        "            'ppo_epochs': 4,  # Note: Called 'ppo_epochs' in VERL but implements GRPO\n",
        "            'model': {\n",
        "                'model_path': 'ByteDance-Seed/UI-TARS-2B-SFT',\n",
        "                'trust_remote_code': True,\n",
        "            },\n",
        "            'optim': {'lr': 1e-6, 'strategy': 'adamw'},\n",
        "            'clip_ratio_low': 0.2,\n",
        "            'clip_ratio_high': 0.3,\n",
        "        },\n",
        "        'rollout': {\n",
        "            'temperature': 0.7,\n",
        "            'n': 8,  # 8 rollouts per task\n",
        "        },\n",
        "    },\n",
        "    'env': {\n",
        "        'num_envs': 2,\n",
        "        'max_steps': 16,  # 16 steps for proper exploration\n",
        "        'provider': 'docker',\n",
        "    },\n",
        "    'trainer': {\n",
        "        'total_episodes': 2,  # 2 epochs\n",
        "        'logger': ['console', 'wandb'],\n",
        "        'project_name': 'arpo-smoke-test',\n",
        "        'experiment_name': 'smoke-4tasks-grpo',\n",
        "        'n_gpus_per_node': 1,\n",
        "        'save_freq': 1,\n",
        "    },\n",
        "}\n",
        "\n",
        "with open('smoke_test.yaml', 'w') as f:\n",
        "    yaml.dump(config, f)\n",
        "\n",
        "print('\u2705 ARPO Smoke Test Config (GRPO + Experience Replay):')\n",
        "print('  Tasks: 4')\n",
        "print('  Envs: 2')\n",
        "print('  Rollouts: 8 per task')\n",
        "print('  Max steps: 16 (proper exploration)')\n",
        "print('  Epochs: 2')\n",
        "print('  GRPO update passes: 4')\n",
        "print('  Batch size: 2')\n",
        "print()\n",
        "print('Optimization steps:')\n",
        "print('  4 tasks \u00d7 8 rollouts \u00d7 2 epochs = 64 total rollouts')\n",
        "print('  64 rollouts \u00f7 2 batch = 32 batches')\n",
        "print('  32 batches \u00d7 4 passes = 128 optimization steps \u2705')\n",
        "print()\n",
        "print('Expected: ~1-1.5 hours (16 steps \u00d7 8 rollouts \u00d7 4 tasks)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Run Smoke Test\n",
        "\n",
        "This verifies:\n",
        "1. VERL pipeline works\n",
        "2. Experience replay functions\n",
        "3. Checkpoints save\n",
        "4. Loss converges\n",
        "\n",
        "**~30-60 minutes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m verl.trainer.main config=smoke_test.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7. Verify Results"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check checkpoints saved\n",
        "!ls -lh checkpoints*/\n",
        "\n",
        "# Check results\n",
        "!ls -lh results*/\n",
        "\n",
        "print('\\n\u2705 If you see checkpoints and results, smoke test passed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Success Checklist\n",
        "\n",
        "After smoke test completes:\n",
        "\n",
        "- [ ] Training completed without crashes\n",
        "- [ ] Loss values are finite (not NaN)\n",
        "- [ ] Loss changes over training (not stuck)\n",
        "- [ ] Checkpoints saved in checkpoints/ folder\n",
        "- [ ] Can load checkpoint for evaluation\n",
        "- [ ] wandb shows training curves\n",
        "- [ ] Experience replay buffer populated\n",
        "\n",
        "**If all pass \u2192 Ready to scale to 32 or 128 tasks!**\n",
        "\n",
        "**wandb**: https://wandb.ai/hanszhu05/arpo-smoke-test"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}