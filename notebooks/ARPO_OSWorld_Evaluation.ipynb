{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ARPO OSWorld Evaluation - Chrome Tasks (Original vs Noisy)\n",
        "\n",
        "This notebook evaluates **10 Chrome tasks** (original + noisy versions) to test model robustness.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "1. **GPU Server Running**: Start `notebooks/GPU_Server_for_OSWorld.ipynb` on Colab first\n",
        "2. **VMware VM Ready**: Your Mac OSWorld VM should be set up and ready\n",
        "3. **Server URL**: Copy the ngrok URL from the GPU server notebook\n",
        "\n",
        "---\n",
        "\n",
        "## Setup Summary\n",
        "\n",
        "- **Model**: ARPO UITARS 7B (running on Colab GPU)\n",
        "- **Tasks**: 10 Chrome tasks (original) + 10 Chrome tasks (noisy)\n",
        "- **Total**: 20 tasks\n",
        "- **Expected Time**: ~1.5 hours (20 tasks √ó ~4.5 min per task)\n",
        "- **Results**: Saved to `results/gpu_eval_chrome_10/` and `results/gpu_eval_chrome_noisy_10/`\n",
        "- **Dataset**: 128 total tasks (18 Chrome, 19 VS Code, 19 GIMP, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Check Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Working directory: /Users/hanszhu/Desktop/ARPO_replicate\n",
            "‚úÖ OSWorld path: /Users/hanszhu/Desktop/ARPO_replicate/OSWorld\n",
            "‚úÖ Test data: /Users/hanszhu/Desktop/ARPO_replicate/test_data/osworld_examples\n",
            "‚úÖ Results will be saved to: /Users/hanszhu/Desktop/ARPO_replicate/results/gpu_eval\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Get project root\n",
        "ARPO_ROOT = Path(\"/Users/hanszhu/Desktop/ARPO_replicate\")\n",
        "os.chdir(ARPO_ROOT)\n",
        "\n",
        "# Add OSWorld to path\n",
        "sys.path.insert(0, str(ARPO_ROOT / \"OSWorld\"))\n",
        "\n",
        "print(f\"‚úÖ Working directory: {os.getcwd()}\")\n",
        "print(f\"‚úÖ OSWorld path: {ARPO_ROOT / 'OSWorld'}\")\n",
        "print(f\"‚úÖ Test data: {ARPO_ROOT / 'test_data' / 'osworld_examples'}\")\n",
        "print(f\"‚úÖ Results will be saved to: {ARPO_ROOT / 'results' / 'gpu_eval'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure GPU Server URL\n",
        "\n",
        "**‚ö†Ô∏è Important**: Update this with your actual ngrok URL from the GPU server notebook!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ GPU Server is reachable: https://miller-unshapeable-melany.ngrok-free.dev\n",
            "‚úÖ Server status: {'model': 'arpo-uitars-7b', 'status': 'healthy'}\n"
          ]
        }
      ],
      "source": [
        "# UPDATE THIS WITH YOUR NGROK URL FROM COLAB!\n",
        "GPU_SERVER_URL = \"https://miller-unshapeable-melany.ngrok-free.dev\"  # Example: https://1234-56-78-90-12.ngrok.io\n",
        "\n",
        "# Test connection\n",
        "import requests\n",
        "\n",
        "if GPU_SERVER_URL == \"https://YOUR-NGROK-URL.ngrok.io\":\n",
        "    print(\"‚ö†Ô∏è  WARNING: You need to update GPU_SERVER_URL with your actual ngrok URL!\")\n",
        "    print(\"   Get it from the GPU server notebook (Cell 4 output)\")\n",
        "else:\n",
        "    try:\n",
        "        response = requests.get(f\"{GPU_SERVER_URL}/health\", timeout=5)\n",
        "        if response.status_code == 200:\n",
        "            print(f\"‚úÖ GPU Server is reachable: {GPU_SERVER_URL}\")\n",
        "            print(f\"‚úÖ Server status: {response.json()}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Server returned status {response.status_code}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Cannot reach server: {e}\")\n",
        "        print(f\"   Make sure GPU server notebook is running on Colab!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Update OSWorld Agent Configuration\n",
        "\n",
        "Update the agent to use the Colab GPU server instead of localhost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è  Agent already configured (not using localhost)\n",
            "   Current config will be used\n"
          ]
        }
      ],
      "source": [
        "import fileinput\n",
        "import shutil\n",
        "\n",
        "# Backup original\n",
        "agent_file = ARPO_ROOT / \"OSWorld\" / \"mm_agents\" / \"uitars_agent.py\"\n",
        "backup_file = agent_file.with_suffix('.py.backup')\n",
        "\n",
        "if not backup_file.exists():\n",
        "    shutil.copy(agent_file, backup_file)\n",
        "    print(f\"‚úÖ Created backup: {backup_file}\")\n",
        "\n",
        "# Update base_url\n",
        "agent_content = agent_file.read_text()\n",
        "if \"localhost:9000\" in agent_content:\n",
        "    updated_content = agent_content.replace(\n",
        "        'base_url=\"http://localhost:9001/v1\"',\n",
        "        f'base_url=\"{GPU_SERVER_URL}/v1\"'\n",
        "    )\n",
        "    agent_file.write_text(updated_content)\n",
        "    print(f\"‚úÖ Updated agent to use: {GPU_SERVER_URL}/v1\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Agent already configured (not using localhost)\")\n",
        "    print(f\"   Current config will be used\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Run Evaluation on Original Chrome Tasks (10 tasks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üßπ Clearing previous results from: /Users/hanszhu/Desktop/ARPO_replicate/results/gpu_eval_chrome_10\n",
            "üöÄ Starting evaluation on 10 CHROME tasks (original)...\n",
            "üìÅ Results will be saved to: /Users/hanszhu/Desktop/ARPO_replicate/results/gpu_eval_chrome_10\n",
            "‚è±Ô∏è  Expected time: ~45 minutes (10 tasks √ó ~4.5 min)\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "‚úÖ Evaluation complete in 27.6 minutes!\n",
            "======================================================================\n",
            "\n",
            "üìä Last 50 lines of output:\n",
            "I finally found the right place! On the Safe Browsing settings page, I noticed three protection level options: Enhanced Protection, Standard Protection, and No Protection. Currently, Standard Protection is selected, but that won't work for our needs; we require stricter security measures. I observed that Enhanced Protection offers real-time AI-powered protection against unsafe websites, downloads, and extensions, which is exactly what we need. Let me click on this option to activate Chrome's safe browsing warning feature.\n",
            "'''\n",
            "\n",
            "pyautogui.click(680.745, 375.824, button='left')\n",
            "\u001b[1;33m[2026-01-19 18:07:54,514 \u001b[31mINFO \u001b[32mpython/125-MainProcess\u001b[1;33m] \u001b[0mCommand executed successfully: {\n",
            "  \"error\": \"\",\n",
            "  \"output\": \"\",\n",
            "  \"returncode\": 0,\n",
            "  \"status\": \"success\"\n",
            "}\n",
            "\n",
            "\u001b[1;33m[2026-01-19 18:07:54,683 \u001b[31mINFO \u001b[32mpython/32-MainProcess\u001b[1;33m] \u001b[0mGot screenshot successfully\n",
            "\u001b[1;33m[2026-01-19 18:07:54,683 \u001b[31mINFO \u001b[32mlib_run_single/53-MainProcess\u001b[1;33m] \u001b[0mReward: 0.00\n",
            "\u001b[1;33m[2026-01-19 18:07:54,683 \u001b[31mINFO \u001b[32mlib_run_single/54-MainProcess\u001b[1;33m] \u001b[0mDone: False\n",
            "Prediction: Thought: I have successfully enabled the Enhanced Protection option on the Safe Browsing settings page. This feature is exactly what we need‚Äîit offers real-time AI protection, constantly scanning and analyzing our browsing activities to promptly alert us when we encounter unsafe websites. I have set up the security feature as required, and now users will receive warnings when visiting potentially harmful sites. It seems that our task has been successfully completed.\n",
            "Action: finished(content='Â∑≤‰∏∫‰Ω†ÂºÄÂêØChromeÁöÑËøô‰∏™ÂÆâÂÖ®ÂäüËÉΩÔºåÁé∞Âú®ÂÆÉ‰ºöÂú®‰Ω†ËÆøÈóÆÂèØËÉΩÂ≠òÂú®Âç±Èô©ÁöÑÁΩëÁ´ôÊó∂ÂèëÂá∫Ë≠¶Âëä„ÄÇ')\n",
            "\u001b[1;33m[2026-01-19 18:08:05,891 \u001b[31mINFO \u001b[32mlib_run_single/50-MainProcess\u001b[1;33m] \u001b[0mStep 9: DONE\n",
            "\u001b[1;33m[2026-01-19 18:08:06,093 \u001b[31mINFO \u001b[32mpython/32-MainProcess\u001b[1;33m] \u001b[0mGot screenshot successfully\n",
            "\u001b[1;33m[2026-01-19 18:08:06,093 \u001b[31mINFO \u001b[32mlib_run_single/53-MainProcess\u001b[1;33m] \u001b[0mReward: 0.00\n",
            "\u001b[1;33m[2026-01-19 18:08:06,093 \u001b[31mINFO \u001b[32mlib_run_single/54-MainProcess\u001b[1;33m] \u001b[0mDone: True\n",
            "\u001b[1;33m[2026-01-19 18:08:06,094 \u001b[31mINFO \u001b[32mlib_run_single/88-MainProcess\u001b[1;33m] \u001b[0mThe episode is done.\n",
            "\u001b[1;33m[2026-01-19 18:08:06,238 \u001b[31mINFO \u001b[32msetup/269-MainProcess\u001b[1;33m] \u001b[0mCommand executed successfully: pkill chrome -> {\n",
            "  \"error\": \"\",\n",
            "  \"output\": \"\",\n",
            "  \"returncode\": 0,\n",
            "  \"status\": \"success\"\n",
            "}\n",
            "\n",
            "\u001b[1;33m[2026-01-19 18:08:06,238 \u001b[31mINFO \u001b[32msetup/66-MainProcess\u001b[1;33m] \u001b[0mSETUP: _execute_setup({'command': 'pkill chrome', 'shell': 'true'})\n",
            "\u001b[1;33m[2026-01-19 18:08:06,961 \u001b[31mINFO \u001b[32mpython/125-MainProcess\u001b[1;33m] \u001b[0mCommand executed successfully: {\n",
            "  \"error\": \"\",\n",
            "  \"output\": \"Linux\\n\",\n",
            "  \"returncode\": 0,\n",
            "  \"status\": \"success\"\n",
            "}\n",
            "\n",
            "\u001b[1;33m[2026-01-19 18:08:07,522 \u001b[31mINFO \u001b[32mpython/125-MainProcess\u001b[1;33m] \u001b[0mCommand executed successfully: {\n",
            "  \"error\": \"\",\n",
            "  \"output\": \"/home/user/snap/chromium/common/chromium/Default/Preferences\\n\",\n",
            "  \"returncode\": 0,\n",
            "  \"status\": \"success\"\n",
            "}\n",
            "\n",
            "\u001b[1;33m[2026-01-19 18:08:07,571 \u001b[31mINFO \u001b[32mpython/98-MainProcess\u001b[1;33m] \u001b[0mFile downloaded successfully\n",
            "true true\n",
            "\u001b[1;33m[2026-01-19 18:08:07,581 \u001b[31mINFO \u001b[32mlib_run_single/92-MainProcess\u001b[1;33m] \u001b[0mResult: 1.00\n",
            "\u001b[1;33m[2026-01-19 18:08:09,337 \u001b[31mINFO \u001b[32mpython/339-MainProcess\u001b[1;33m] \u001b[0mRecording stopped successfully\n",
            "\u001b[1;33m[2026-01-19 18:08:09,344 \u001b[31mINFO \u001b[32mprovider/101-MainProcess\u001b[1;33m] \u001b[0mStopping VMware VM...\n",
            "\u001b[1;33m[2026-01-19 18:08:12,481 \u001b[31mINFO \u001b[32mrun_uitars/227-MainProcess\u001b[1;33m] \u001b[0mAverage score: 0.5555555555555556\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "# Create/clear results directory\n",
        "results_dir_chrome = ARPO_ROOT / \"results\" / \"gpu_eval_chrome_10\"\n",
        "\n",
        "# Clear previous results if they exist\n",
        "if results_dir_chrome.exists():\n",
        "    print(f\"üßπ Clearing previous results from: {results_dir_chrome}\")\n",
        "    shutil.rmtree(results_dir_chrome)\n",
        "    \n",
        "results_dir_chrome.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"üöÄ Starting evaluation on 10 CHROME tasks (original)...\")\n",
        "print(f\"üìÅ Results will be saved to: {results_dir_chrome}\")\n",
        "print(f\"‚è±Ô∏è  Expected time: ~45 minutes (10 tasks √ó ~4.5 min)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Run OSWorld evaluation\n",
        "cmd = [\n",
        "    \"python\", \"run_uitars.py\",\n",
        "    \"--headless\",\n",
        "    \"--observation_type\", \"screenshot\",\n",
        "    \"--max_steps\", \"15\",\n",
        "    \"--model\", \"arpo-uitars-7b\",\n",
        "    \"--temperature\", \"0.6\",\n",
        "    \"--max_tokens\", \"256\",\n",
        "    \"--test_config_base_dir\", \"../test_data/osworld_examples\",\n",
        "    \"--test_all_meta_path\", \"../test_data/osworld_examples/test_chrome_10.json\",\n",
        "    \"--result_dir\", str(results_dir_chrome),\n",
        "]\n",
        "\n",
        "try:\n",
        "    # Run from OSWorld directory\n",
        "    result = subprocess.run(\n",
        "        cmd,\n",
        "        cwd=ARPO_ROOT / \"OSWorld\",\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        timeout=3600  # 60 min timeout (10 tasks √ó ~4.5 min + buffer)\n",
        "    )\n",
        "    \n",
        "    elapsed = time.time() - start_time\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"‚úÖ Evaluation complete in {elapsed/60:.1f} minutes!\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Show last 50 lines of output\n",
        "    print(\"\\nüìä Last 50 lines of output:\")\n",
        "    print(\"\\n\".join(result.stdout.split(\"\\n\")[-50:]))\n",
        "    \n",
        "    if result.returncode != 0:\n",
        "        print(f\"\\n‚ö†Ô∏è  Warning: Process returned code {result.returncode}\")\n",
        "        print(\"Last 20 lines of stderr:\")\n",
        "        print(\"\\n\".join(result.stderr.split(\"\\n\")[-20:]))\n",
        "        \n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"‚ùå Evaluation timed out after 60 minutes\")\n",
        "    print(\"‚ö†Ô∏è  Some tasks may have completed - check results folder\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. View Results for Original Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç Analyzing CHROME task results...\n",
            "\n",
            "======================================================================\n",
            "üìä Results Summary (9 tasks)\n",
            "======================================================================\n",
            "‚úÖ PASS | 368d9ba4-203c-40c1-9 | Score: 1.00\n",
            "‚ùå FAIL | 2ae9ba84-3a0d-4d4c-8 | Score: 0.00\n",
            "‚úÖ PASS | 9656a811-9b5b-4ddf-9 | Score: 1.00\n",
            "‚úÖ PASS | 2ad9387a-65d8-4e33-a | Score: 1.00\n",
            "‚úÖ PASS | 3720f614-37fd-4d04-8 | Score: 1.00\n",
            "‚ùå FAIL | 06fe7178-4491-4589-8 | Score: 0.00\n",
            "‚ùå FAIL | 0d8b7de3-e8de-4d86-b | Score: 0.00\n",
            "‚úÖ PASS | 3299584d-8f11-4457-b | Score: 1.00\n",
            "‚ùå FAIL | 7b6c7e24-c58a-49fc-a | Score: 0.00\n",
            "======================================================================\n",
            "Average Score: 0.556\n",
            "Success Rate:  55.6% (5/9)\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def analyze_results(result_dir):\n",
        "    \"\"\"Analyze OSWorld evaluation results\"\"\"\n",
        "    results = []\n",
        "    \n",
        "    # Find all result.txt files\n",
        "    for result_file in Path(result_dir).rglob(\"result.txt\"):\n",
        "        task_id = result_file.parent.name\n",
        "        domain = result_file.parent.parent.name\n",
        "        \n",
        "        try:\n",
        "            score = float(result_file.read_text().strip())\n",
        "            results.append({\n",
        "                \"task_id\": task_id,\n",
        "                \"domain\": domain,\n",
        "                \"score\": score\n",
        "            })\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    if not results:\n",
        "        print(\"‚ö†Ô∏è  No results found yet\")\n",
        "        return None\n",
        "    \n",
        "    # Print summary\n",
        "    print(\"=\"*70)\n",
        "    print(f\"üìä Results Summary ({len(results)} tasks)\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    for r in results:\n",
        "        status = \"‚úÖ PASS\" if r[\"score\"] >= 0.9 else \"‚ùå FAIL\"\n",
        "        print(f\"{status} | {r['task_id'][:20]:20s} | Score: {r['score']:.2f}\")\n",
        "    \n",
        "    avg_score = sum(r[\"score\"] for r in results) / len(results)\n",
        "    success_rate = sum(1 for r in results if r[\"score\"] >= 0.9) / len(results) * 100\n",
        "    \n",
        "    print(\"=\"*70)\n",
        "    print(f\"Average Score: {avg_score:.3f}\")\n",
        "    print(f\"Success Rate:  {success_rate:.1f}% ({sum(1 for r in results if r['score'] >= 0.9)}/{len(results)})\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Analyze Chrome tasks\n",
        "print(\"\\nüîç Analyzing CHROME task results...\\n\")\n",
        "chrome_results = analyze_results(results_dir_chrome)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "osworld testing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Starting evaluation on 10 CHROME tasks (noisy)...\n",
            "üìÅ Results will be saved to: /Users/hanszhu/Desktop/ARPO_replicate/results/gpu_eval_chrome_noisy_10\n",
            "‚è±Ô∏è  Expected time: ~45 minutes (10 tasks √ó ~4.5 min)\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "‚úÖ Evaluation complete in 35.2 minutes!\n",
            "======================================================================\n",
            "\n",
            "üìä Last 50 lines of output:\n",
            "I've finally reached the security settings page. I noticed there are three options listed here: Enhanced protection, Standard protection, and No protection. Since we want to ensure the highest level of website safety, Enhanced protection is the best choice. It offers real-time AI protection against dangerous websites, downloads, and extensions, exactly what we need. Let me select this option to enable Chrome's security warning feature.\n",
            "'''\n",
            "\n",
            "pyautogui.click(673.789, 380.769, button='left')\n",
            "\u001b[1;33m[2026-01-19 19:09:27,527 \u001b[31mINFO \u001b[32mpython/125-MainProcess\u001b[1;33m] \u001b[0mCommand executed successfully: {\n",
            "  \"error\": \"\",\n",
            "  \"output\": \"\",\n",
            "  \"returncode\": 0,\n",
            "  \"status\": \"success\"\n",
            "}\n",
            "\n",
            "\u001b[1;33m[2026-01-19 19:09:27,761 \u001b[31mINFO \u001b[32mpython/32-MainProcess\u001b[1;33m] \u001b[0mGot screenshot successfully\n",
            "\u001b[1;33m[2026-01-19 19:09:27,761 \u001b[31mINFO \u001b[32mlib_run_single/53-MainProcess\u001b[1;33m] \u001b[0mReward: 0.00\n",
            "\u001b[1;33m[2026-01-19 19:09:27,761 \u001b[31mINFO \u001b[32mlib_run_single/54-MainProcess\u001b[1;33m] \u001b[0mDone: False\n",
            "Prediction: Thought: I just finished the setup for Enhanced Protection, and the system has automatically enabled this feature for me. Looking at the interface, Enhanced Protection offers real-time AI-driven security protection, which is exactly the website warning functionality we were looking for. It not only alerts us about previously unknown dangerous websites but also provides in-depth analysis of suspicious downloads. Now that the security settings are complete, Chrome will automatically remind us when we encounter any unsafe websites.\n",
            "Action: finished(content='Chrome will automatically alert you when you visit a potentially harmful website. I have already enabled this safety feature by accessing the browser settings and configuring the safe browsing options.')\n",
            "\u001b[1;33m[2026-01-19 19:09:39,617 \u001b[31mINFO \u001b[32mlib_run_single/50-MainProcess\u001b[1;33m] \u001b[0mStep 9: DONE\n",
            "\u001b[1;33m[2026-01-19 19:09:39,823 \u001b[31mINFO \u001b[32mpython/32-MainProcess\u001b[1;33m] \u001b[0mGot screenshot successfully\n",
            "\u001b[1;33m[2026-01-19 19:09:39,823 \u001b[31mINFO \u001b[32mlib_run_single/53-MainProcess\u001b[1;33m] \u001b[0mReward: 0.00\n",
            "\u001b[1;33m[2026-01-19 19:09:39,823 \u001b[31mINFO \u001b[32mlib_run_single/54-MainProcess\u001b[1;33m] \u001b[0mDone: True\n",
            "\u001b[1;33m[2026-01-19 19:09:39,824 \u001b[31mINFO \u001b[32mlib_run_single/88-MainProcess\u001b[1;33m] \u001b[0mThe episode is done.\n",
            "\u001b[1;33m[2026-01-19 19:09:39,924 \u001b[31mINFO \u001b[32msetup/269-MainProcess\u001b[1;33m] \u001b[0mCommand executed successfully: pkill chrome -> {\n",
            "  \"error\": \"\",\n",
            "  \"output\": \"\",\n",
            "  \"returncode\": 0,\n",
            "  \"status\": \"success\"\n",
            "}\n",
            "\n",
            "\u001b[1;33m[2026-01-19 19:09:39,924 \u001b[31mINFO \u001b[32msetup/66-MainProcess\u001b[1;33m] \u001b[0mSETUP: _execute_setup({'command': 'pkill chrome', 'shell': 'true'})\n",
            "\u001b[1;33m[2026-01-19 19:09:40,611 \u001b[31mINFO \u001b[32mpython/125-MainProcess\u001b[1;33m] \u001b[0mCommand executed successfully: {\n",
            "  \"error\": \"\",\n",
            "  \"output\": \"Linux\\n\",\n",
            "  \"returncode\": 0,\n",
            "  \"status\": \"success\"\n",
            "}\n",
            "\n",
            "\u001b[1;33m[2026-01-19 19:09:40,865 \u001b[31mINFO \u001b[32mpython/125-MainProcess\u001b[1;33m] \u001b[0mCommand executed successfully: {\n",
            "  \"error\": \"\",\n",
            "  \"output\": \"/home/user/snap/chromium/common/chromium/Default/Preferences\\n\",\n",
            "  \"returncode\": 0,\n",
            "  \"status\": \"success\"\n",
            "}\n",
            "\n",
            "\u001b[1;33m[2026-01-19 19:09:40,887 \u001b[31mINFO \u001b[32mpython/98-MainProcess\u001b[1;33m] \u001b[0mFile downloaded successfully\n",
            "true true\n",
            "\u001b[1;33m[2026-01-19 19:09:40,895 \u001b[31mINFO \u001b[32mlib_run_single/92-MainProcess\u001b[1;33m] \u001b[0mResult: 1.00\n",
            "\u001b[1;33m[2026-01-19 19:09:41,830 \u001b[31mINFO \u001b[32mpython/339-MainProcess\u001b[1;33m] \u001b[0mRecording stopped successfully\n",
            "\u001b[1;33m[2026-01-19 19:09:41,843 \u001b[31mINFO \u001b[32mprovider/101-MainProcess\u001b[1;33m] \u001b[0mStopping VMware VM...\n",
            "\u001b[1;33m[2026-01-19 19:09:44,967 \u001b[31mINFO \u001b[32mrun_uitars/227-MainProcess\u001b[1;33m] \u001b[0mAverage score: 0.3333333333333333\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "# Create/clear results directory\n",
        "results_dir_chrome_noisy = ARPO_ROOT / \"results\" / \"gpu_eval_chrome_noisy_10\"\n",
        "\n",
        "# Clear previous results if they exist\n",
        "if results_dir_chrome_noisy.exists():\n",
        "    print(f\"üßπ Clearing previous results from: {results_dir_chrome_noisy}\")\n",
        "    shutil.rmtree(results_dir_chrome_noisy)\n",
        "    \n",
        "results_dir_chrome_noisy.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"üöÄ Starting evaluation on 10 CHROME tasks (noisy)...\")\n",
        "print(f\"üìÅ Results will be saved to: {results_dir_chrome_noisy}\")\n",
        "print(f\"‚è±Ô∏è  Expected time: ~45 minutes (10 tasks √ó ~4.5 min)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Run OSWorld evaluation on noisy Chrome tasks\n",
        "cmd = [\n",
        "    \"python\", \"run_uitars.py\",\n",
        "    \"--headless\",\n",
        "    \"--observation_type\", \"screenshot\",\n",
        "    \"--max_steps\", \"15\",\n",
        "    \"--model\", \"arpo-uitars-7b\",\n",
        "    \"--temperature\", \"0.6\",\n",
        "    \"--max_tokens\", \"256\",\n",
        "    \"--test_config_base_dir\", \"../test_data/osworld_examples\",\n",
        "    \"--test_all_meta_path\", \"../test_data/osworld_examples/test_chrome_noisy_10.json\",\n",
        "    \"--result_dir\", str(results_dir_chrome_noisy),\n",
        "]\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(\n",
        "        cmd,\n",
        "        cwd=ARPO_ROOT / \"OSWorld\",\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        timeout=3600  # 60 min timeout (10 tasks √ó ~4.5 min + buffer)\n",
        "    )\n",
        "    \n",
        "    elapsed = time.time() - start_time\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"‚úÖ Evaluation complete in {elapsed/60:.1f} minutes!\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Show last 50 lines\n",
        "    print(\"\\nüìä Last 50 lines of output:\")\n",
        "    print(\"\\n\".join(result.stdout.split(\"\\n\")[-50:]))\n",
        "    \n",
        "    if result.returncode != 0:\n",
        "        print(f\"\\n‚ö†Ô∏è  Warning: Process returned code {result.returncode}\")\n",
        "        print(\"Last 20 lines of stderr:\")\n",
        "        print(\"\\n\".join(result.stderr.split(\"\\n\")[-20:]))\n",
        "        \n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"‚ùå Evaluation timed out after 60 minutes\")\n",
        "    print(\"‚ö†Ô∏è  Some tasks may have completed - check results folder\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. View Results for Noisy Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "print(\"\\nüîç Analyzing NOISY CHROME task results...\\n\")\n",
        "chrome_noisy_results = analyze_results(results_dir_chrome_noisy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'chrome_noisy_results' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chrome_results \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mchrome_noisy_results\u001b[49m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìä CHROME: Original vs Noisy Comparison\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'chrome_noisy_results' is not defined"
          ]
        }
      ],
      "source": [
        "# Check if both result sets exist (must run cells 4-6 and 8-10 first)\n",
        "try:\n",
        "    chrome_results\n",
        "    chrome_noisy_results\n",
        "    has_both = True\n",
        "except NameError:\n",
        "    has_both = False\n",
        "\n",
        "if has_both and chrome_results and chrome_noisy_results:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìä CHROME: Original vs Noisy Comparison\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    orig_avg = sum(r[\"score\"] for r in chrome_results) / len(chrome_results)\n",
        "    noisy_avg = sum(r[\"score\"] for r in chrome_noisy_results) / len(chrome_noisy_results)\n",
        "    \n",
        "    orig_success = sum(1 for r in chrome_results if r[\"score\"] >= 0.9) / len(chrome_results) * 100\n",
        "    noisy_success = sum(1 for r in chrome_noisy_results if r[\"score\"] >= 0.9) / len(chrome_noisy_results) * 100\n",
        "    \n",
        "    print(f\"\\nOriginal Chrome Tasks ({len(chrome_results)}):\")\n",
        "    print(f\"  Average Score:  {orig_avg:.3f}\")\n",
        "    print(f\"  Success Rate:   {orig_success:.1f}%\")\n",
        "    print(f\"  Passed:         {sum(1 for r in chrome_results if r['score'] >= 0.9)}/{len(chrome_results)}\")\n",
        "    \n",
        "    print(f\"\\nNoisy Chrome Tasks ({len(chrome_noisy_results)}):\")\n",
        "    print(f\"  Average Score:  {noisy_avg:.3f}\")\n",
        "    print(f\"  Success Rate:   {noisy_success:.1f}%\")\n",
        "    print(f\"  Passed:         {sum(1 for r in chrome_noisy_results if r['score'] >= 0.9)}/{len(chrome_noisy_results)}\")\n",
        "    \n",
        "    print(f\"\\nRobustness (Noisy/Original):\")\n",
        "    print(f\"  Score Ratio:    {noisy_avg/orig_avg:.2%}\" if orig_avg > 0 else \"  Score Ratio:  N/A\")\n",
        "    print(f\"  Success Ratio:  {noisy_success/orig_success:.2%}\" if orig_success > 0 else \"  Success Ratio:  N/A\")\n",
        "    \n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Expected performance (from ARPO paper)\n",
        "    print(\"\\nüìö Expected Performance (from ARPO paper):\")\n",
        "    print(\"  ARPO UITARS1.5 7B on OSWorld Chrome: ~22.6% success rate\")\n",
        "    print(\"  (10 tasks is a good sample for initial testing)\")\n",
        "    print(\"=\"*70)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Please run cells in order:\")\n",
        "    print(\"   1. Cell 8: Run original Chrome tasks\")\n",
        "    print(\"   2. Cell 10: Analyze original results\")\n",
        "    print(\"   3. Cell 12: Run noisy Chrome tasks\")\n",
        "    print(\"   4. Cell 14: Analyze noisy results\")\n",
        "    print(\"   5. Then run this cell to compare\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Inspect Individual Task Trajectories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def view_trajectory(result_dir, task_id):\n",
        "    \"\"\"View detailed trajectory for a specific task\"\"\"\n",
        "    traj_file = None\n",
        "    for f in Path(result_dir).rglob(f\"{task_id}/traj.jsonl\"):\n",
        "        traj_file = f\n",
        "        break\n",
        "    \n",
        "    if not traj_file:\n",
        "        print(f\"‚ö†Ô∏è  Trajectory not found for {task_id}\")\n",
        "        return\n",
        "    \n",
        "    print(f\"\\nüìù Trajectory: {task_id}\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    with open(traj_file) as f:\n",
        "        steps = [json.loads(line) for line in f]\n",
        "    \n",
        "    for i, step in enumerate(steps, 1):\n",
        "        print(f\"\\nStep {i}:\")\n",
        "        if \"prediction\" in step:\n",
        "            pred = step[\"prediction\"]\n",
        "            if isinstance(pred, str):\n",
        "                # Show first 200 chars\n",
        "                print(f\"  Prediction: {pred[:200]}...\")\n",
        "            else:\n",
        "                print(f\"  Prediction: {pred}\")\n",
        "        if \"action\" in step:\n",
        "            print(f\"  Action: {step['action']}\")\n",
        "        if \"reward\" in step:\n",
        "            print(f\"  Reward: {step['reward']}\")\n",
        "        if \"done\" in step:\n",
        "            print(f\"  Done: {step['done']}\")\n",
        "    \n",
        "    print(\"=\"*70)\n",
        "\n",
        "# Example: View first task from Chrome results\n",
        "if chrome_results:\n",
        "    first_task = chrome_results[0][\"task_id\"]\n",
        "    print(f\"\\nüîç Viewing trajectory for first Chrome task: {first_task}\")\n",
        "    view_trajectory(results_dir_chrome, first_task)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No results available yet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Restore Original Agent Configuration\n",
        "\n",
        "After evaluation, restore the agent to use localhost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Restore backup\n",
        "if backup_file.exists():\n",
        "    shutil.copy(backup_file, agent_file)\n",
        "    print(f\"‚úÖ Restored original agent configuration\")\n",
        "    print(f\"   Agent is now using localhost:9000 again\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No backup found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### What This Notebook Does\n",
        "\n",
        "1. ‚úÖ Connects to Colab GPU server (via ngrok)\n",
        "2. ‚úÖ Runs 10 original Chrome tasks\n",
        "3. ‚úÖ Runs 10 noisy Chrome tasks\n",
        "4. ‚úÖ Analyzes results and computes success rates\n",
        "5. ‚úÖ Compares robustness (original vs noisy)\n",
        "6. ‚úÖ Restores original configuration\n",
        "\n",
        "### Results Location\n",
        "\n",
        "- **Original Chrome**: `results/gpu_eval_chrome_10/`\n",
        "- **Noisy Chrome**: `results/gpu_eval_chrome_noisy_10/`\n",
        "\n",
        "Each task folder contains:\n",
        "- `traj.jsonl` - Step-by-step log\n",
        "- `result.txt` - Final score (0.0 or 1.0)\n",
        "- `step_*.png` - Screenshots\n",
        "- `recording.mp4` - Video\n",
        "\n",
        "### Dataset Info\n",
        "\n",
        "- **Total tasks**: 128 across 10 domains\n",
        "- **Chrome tasks**: Testing first 10 (out of 18 available)\n",
        "- **Other domains available**: gimp (19), vs_code (19), libreoffice_calc (12), etc.\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Analyze failed Chrome tasks to understand errors\n",
        "- Compare with ARPO paper results (~22.6% on full OSWorld)\n",
        "- Test other domains if needed\n",
        "- Use insights for further training/fine-tuning"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "arpo",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
