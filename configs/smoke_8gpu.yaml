# ARPO Smoke Test Configuration - 8 GPUs, 4 tasks, ~15-20 minutes
# Optimized for 8 GPU cluster with Docker support

data:
  train_files: evaluation_examples/test_smoke_4.json  # 4 tasks only
  val_files: evaluation_examples/test_smoke_4.json
  prompt_key: instruction
  answer_key: ""  # Empty string instead of null
  image_key: images
  max_prompt_length: 32768
  max_response_length: 4096
  rollout_batch_size: 16  # Must be divisible by global_batch_size
  val_batch_size: -1
  shuffle: true
  seed: 1
  max_pixels: 2116800
  min_pixels: 2800

algorithm:
  adv_estimator: grpo
  disable_kl: true  # No KL divergence (ARPO)
  use_kl_loss: false
  kl_coef: 0
  enable_replay: true  # Experience replay buffer (key ARPO feature!)

worker:
  actor:
    global_batch_size: 16  # 2 per GPU (16 / 8 GPUs)
    micro_batch_size_per_device_for_update: 2
    micro_batch_size_per_device_for_experience: 2
    max_grad_norm: 1.0
    padding_free: false
    ulysses_sequence_parallel_size: 1
    ppo_epochs: 1
    clip_ratio_low: 0.2
    clip_ratio_high: 0.3
    model:
      model_path: ByteDance-Seed/UI-TARS-2B-SFT
      enable_gradient_checkpointing: true
      trust_remote_code: true
      freeze_vision_tower: false
      override_config:
        _attn_implementation: "eager"  # Disable flash_attn
    optim:
      lr: 1.0e-6
      weight_decay: 1.0e-2
      strategy: adamw
      lr_warmup_ratio: 0.05
    fsdp:
      enable_full_shard: true  # Enable for multi-GPU
      enable_cpu_offload: false
      enable_rank0_init: true
    offload:
      offload_params: false
      offload_optimizer: false

  rollout:
    temperature: 0.7
    n: 2  # GRPO requires n > 1
    gpu_memory_utilization: 0.11  # Slightly higher for KV cache  # GPU available
    enforce_eager: false
    enable_chunked_prefill: false
    tensor_parallel_size: 1
    limit_images: 10
    max_num_batched_tokens: 40960  # Must be > prompt(32768) + response(4096)
    val_override_config:
      temperature: 0.5
      n: 1

  ref:
    fsdp:
      enable_full_shard: true  # Enable for multi-GPU
      enable_cpu_offload: false
    offload:
      offload_params: false

  reward:
    reward_type: function
    score_function: math
    skip_special_tokens: true

env:
  num_envs: 16  # 2 per GPU (16 Docker containers)
  max_steps: 16

trainer:
  total_episodes: 1  # 1 epoch for smoke test
  logger: ["console", "wandb"]
  project_name: arpo-smoke-test
  experiment_name: uitars_2b_4tasks_8gpu
  n_gpus_per_node: 8  # Use all 8 GPUs
  nnodes: 1
