# ARPO Training Configuration for UI-TARS-2B on Mac CPU
# Adapted from examples/config.yaml for Mac with VMware

data:
  train_files: evaluation_examples/train_subset8.json  # 8 tasks for Mac
  val_files: evaluation_examples/train_subset8.json
  prompt_key: instruction
  answer_key: null
  image_key: images
  max_prompt_length: 32768  # Reduced for 2B model
  max_response_length: 4096
  rollout_batch_size: 1  # Single batch for CPU
  val_batch_size: -1
  shuffle: true
  seed: 1
  max_pixels: 2116800  # 16384 * 28 * 28 / 8 (reduced for CPU)
  min_pixels: 2800  # 100 * 28

algorithm:
  adv_estimator: grpo
  disable_kl: true  # No KL divergence (ARPO)
  use_kl_loss: false
  kl_coef: 0
  enable_replay: true  # Experience replay buffer (key ARPO feature!)

worker:
  actor:
    global_batch_size: 2  # Minimal for CPU
    micro_batch_size_per_device_for_update: 1
    micro_batch_size_per_device_for_experience: 1
    max_grad_norm: 1.0
    padding_free: false  # Disable for CPU
    ulysses_sequence_parallel_size: 1
    ppo_epochs: 1
    clip_ratio_low: 0.2  # From paper
    clip_ratio_high: 0.3  # From paper
    model:
      model_path: ByteDance-Seed/UI-TARS-2B-SFT
      enable_gradient_checkpointing: true
      trust_remote_code: true
      freeze_vision_tower: false
    optim:
      lr: 1.0e-6  # From paper
      weight_decay: 1.0e-2
      strategy: adamw  # CPU uses float32, not bf16
      lr_warmup_ratio: 0.05
    fsdp:
      enable_full_shard: false  # Disable FSDP for CPU single device
      enable_cpu_offload: false
      enable_rank0_init: true
    offload:
      offload_params: false
      offload_optimizer: false

  rollout:
    temperature: 0.7  # Lower for CPU (faster, more deterministic)
    n: 1  # Single rollout per task
    gpu_memory_utilization: 0.0  # CPU only
    enforce_eager: true  # For CPU
    enable_chunked_prefill: false
    tensor_parallel_size: 1
    limit_images: 10  # Reduced for 2B model
    max_num_batched_tokens: 32768
    val_override_config:
      temperature: 0.5
      n: 1
    # For local inference server
    use_external_server: true
    server_url: "http://localhost:9000/v1"

  ref:
    # No reference model needed when disable_kl=true
    fsdp:
      enable_full_shard: false
      enable_cpu_offload: false
    offload:
      offload_params: false

  reward:
    reward_type: osworld  # OSWorld-specific reward
    score_function: osworld_eval
    skip_special_tokens: true

env:
  num_envs: 1  # Single VMware VM for Mac
  max_steps: 10  # Reduced from 15
  screen_size: [1920, 1080]
  provider: vmware  # VMware Fusion for macOS
  os_type: Ubuntu
  headless: true

trainer:
  total_episodes: 10  # 10 epochs for full training
  logger: ["console", "wandb"]
  project_name: arpo-uitars-training
  experiment_name: uitars_2b_128tasks
  wandb_entity: "YOUR-WANDB-ENTITY"  # ⬅️ UPDATE THIS
  n_gpus_per_node: 0  # CPU only
  nnodes: 1
  val_freq: 2  # Validate every 2 epochs
  val_before_train: true
  val_only: false
  val_generations_to_log: 2
  save_freq: 2  # Save every 2 epochs
  save_limit: 3
  save_checkpoint_path: checkpoints_2b/
  load_checkpoint_path: null
  use_cpu: true  # Force CPU mode
